{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stilltasty(index,category):\n",
    "    # URL of the page to scrape\n",
    "    url = f'https://www.stilltasty.com/Fooditems/index/{index}'\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        #Get item name\n",
    "        item_name = soup.find('h2').text.strip()\n",
    "\n",
    "        # Find storage location elements\n",
    "        storage_location_elements = soup.find_all('div', class_='food-storage-left')\n",
    "        # Initialize a dictionary to store values\n",
    "        shelf_life = {}\n",
    "        # Loop through storage location elements and find the associated shelf life\n",
    "        for e in storage_location_elements:\n",
    "            storage_location = e.text.strip()\n",
    "            # Find associated shelf life information\n",
    "            shelf_life_info_element = e.find_next_sibling('div')\n",
    "            shelf_life_info = shelf_life_info_element.text.strip()\n",
    "            shelf_life[storage_location] = shelf_life_info\n",
    "        \n",
    "        #Find food tips\n",
    "        tips = soup.find('div', class_='food-tips').text.strip()\n",
    "        #Remove Author Info\n",
    "        n = tips.find('About Our Author')\n",
    "        tips = tips[:n]\n",
    "\n",
    "        return {'item_name': item_name, 'category': category, 'url': url, 'shelf_life': shelf_life, 'food_tips': tips}\n",
    "    else:\n",
    "        # Print an error message if the request was not successful\n",
    "        print(f\"Error: Failed to retrieve data from {url}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_numbers(url,target_string,get_names=False):\n",
    "    index_numbers = []\n",
    "    object_names = []\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find all links with href attribute containing target_string\n",
    "        links = soup.find_all('a', href=lambda href: href and target_string in href)\n",
    "        #Remove image links\n",
    "        links = [link for link in links if not link.find('img')]\n",
    "        # Extract index numbers from href attributes\n",
    "        for link in links:\n",
    "            href = link['href']\n",
    "            index_number = href.split('/')[-1]\n",
    "            index_numbers.append(index_number)\n",
    "            if get_names:\n",
    "                object_name = link.text.strip()\n",
    "                object_names.append(object_name)\n",
    "            \n",
    "        return index_numbers, object_names \n",
    "    \n",
    "    else:\n",
    "        # Print an error message if the request was not successful\n",
    "        print(f\"Error: Failed to retrieve data from {url}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26', '25', '9', '27', '7', '28', '6', '31', '30', '5']\n",
      "['Fruits', 'Vegetables', 'Dairy & Eggs', 'Meat & Poultry', 'Fish & Shellfish', 'Nuts, Grains & Pasta', 'Condiments & Oils', 'Snacks & Baked Goods', 'Herbs & Spices', 'Beverages']\n"
     ]
    }
   ],
   "source": [
    "# URL of the StillTasty index page\n",
    "url = 'https://www.stilltasty.com/Fooditems/index'\n",
    "target_string = \"/searchitems/index/\"\n",
    "category_index_numbers, categories = get_index_numbers(url,target_string,True)\n",
    "print(category_index_numbers)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26', '26?page=2', '26?page=3', '26?page=4', '26?page=5', '26?page=6', '26?page=7', '26?page=8', '26?page=9']\n",
      "Now scraping index 26\n",
      "Completed index 26\n",
      "Now scraping index 26?page=2\n",
      "Completed index 26?page=2\n",
      "Now scraping index 26?page=3\n",
      "Completed index 26?page=3\n",
      "Now scraping index 26?page=4\n",
      "Completed index 26?page=4\n",
      "Now scraping index 26?page=5\n",
      "Completed index 26?page=5\n",
      "Now scraping index 26?page=6\n",
      "Completed index 26?page=6\n",
      "Now scraping index 26?page=7\n",
      "Completed index 26?page=7\n",
      "Now scraping index 26?page=8\n",
      "Completed index 26?page=8\n",
      "Now scraping index 26?page=9\n",
      "Completed index 26?page=9\n",
      "Getting new pages\n",
      "['25', '25?page=2', '25?page=3', '25?page=4', '25?page=5', '25?page=6', '25?page=7', '25?page=8', '25?page=9']\n",
      "Now scraping index 25\n",
      "Completed index 25\n",
      "Now scraping index 25?page=2\n",
      "Completed index 25?page=2\n",
      "Now scraping index 25?page=3\n",
      "Completed index 25?page=3\n",
      "Now scraping index 25?page=4\n",
      "Completed index 25?page=4\n",
      "Now scraping index 25?page=5\n",
      "Completed index 25?page=5\n",
      "Now scraping index 25?page=6\n",
      "Completed index 25?page=6\n",
      "Now scraping index 25?page=7\n",
      "Completed index 25?page=7\n",
      "Now scraping index 25?page=8\n",
      "Completed index 25?page=8\n",
      "Now scraping index 25?page=9\n",
      "Completed index 25?page=9\n",
      "Getting new pages\n",
      "['25?page=10', '25?page=11', '25?page=12', '25?page=13']\n",
      "Now scraping index 25?page=10\n",
      "Completed index 25?page=10\n",
      "Now scraping index 25?page=11\n",
      "Completed index 25?page=11\n",
      "Now scraping index 25?page=12\n",
      "Completed index 25?page=12\n",
      "Now scraping index 25?page=13\n",
      "Completed index 25?page=13\n",
      "Getting new pages\n",
      "['25?page=14']\n",
      "Now scraping index 25?page=14\n",
      "Completed index 25?page=14\n",
      "Getting new pages\n",
      "['9', '9?page=2', '9?page=3', '9?page=4', '9?page=5', '9?page=6', '9?page=7', '9?page=8']\n",
      "Now scraping index 9\n",
      "Completed index 9\n",
      "Now scraping index 9?page=2\n",
      "Completed index 9?page=2\n",
      "Now scraping index 9?page=3\n",
      "Completed index 9?page=3\n",
      "Now scraping index 9?page=4\n",
      "Completed index 9?page=4\n",
      "Now scraping index 9?page=5\n",
      "Completed index 9?page=5\n",
      "Now scraping index 9?page=6\n",
      "Completed index 9?page=6\n",
      "Now scraping index 9?page=7\n",
      "Completed index 9?page=7\n",
      "Now scraping index 9?page=8\n",
      "Completed index 9?page=8\n",
      "Getting new pages\n",
      "['27', '27?page=2', '27?page=3', '27?page=4', '27?page=5', '27?page=6', '27?page=7', '27?page=8', '27?page=9']\n",
      "Now scraping index 27\n",
      "Completed index 27\n",
      "Now scraping index 27?page=2\n",
      "Completed index 27?page=2\n",
      "Now scraping index 27?page=3\n",
      "Completed index 27?page=3\n",
      "Now scraping index 27?page=4\n",
      "Completed index 27?page=4\n",
      "Now scraping index 27?page=5\n",
      "Completed index 27?page=5\n",
      "Now scraping index 27?page=6\n",
      "Completed index 27?page=6\n",
      "Now scraping index 27?page=7\n",
      "Completed index 27?page=7\n",
      "Now scraping index 27?page=8\n",
      "Completed index 27?page=8\n",
      "Now scraping index 27?page=9\n",
      "Completed index 27?page=9\n",
      "Getting new pages\n",
      "['27?page=10', '27?page=11', '27?page=12', '27?page=13']\n",
      "Now scraping index 27?page=10\n",
      "Completed index 27?page=10\n",
      "Now scraping index 27?page=11\n",
      "Completed index 27?page=11\n",
      "Now scraping index 27?page=12\n",
      "Completed index 27?page=12\n",
      "Now scraping index 27?page=13\n",
      "Completed index 27?page=13\n",
      "Getting new pages\n",
      "['27?page=14']\n",
      "Now scraping index 27?page=14\n",
      "Completed index 27?page=14\n",
      "Getting new pages\n",
      "['7', '7?page=2', '7?page=3', '7?page=4', '7?page=5', '7?page=6', '7?page=7', '7?page=8']\n",
      "Now scraping index 7\n",
      "Completed index 7\n",
      "Now scraping index 7?page=2\n",
      "Completed index 7?page=2\n",
      "Now scraping index 7?page=3\n",
      "Completed index 7?page=3\n",
      "Now scraping index 7?page=4\n",
      "Completed index 7?page=4\n",
      "Now scraping index 7?page=5\n",
      "Completed index 7?page=5\n",
      "Now scraping index 7?page=6\n",
      "Completed index 7?page=6\n",
      "Now scraping index 7?page=7\n",
      "Completed index 7?page=7\n",
      "Now scraping index 7?page=8\n",
      "Completed index 7?page=8\n",
      "Getting new pages\n",
      "['28', '28?page=2', '28?page=3', '28?page=4', '28?page=5', '28?page=6', '28?page=7', '28?page=8', '28?page=9']\n",
      "Now scraping index 28\n",
      "Completed index 28\n",
      "Now scraping index 28?page=2\n",
      "Completed index 28?page=2\n",
      "Now scraping index 28?page=3\n",
      "Completed index 28?page=3\n",
      "Now scraping index 28?page=4\n",
      "Completed index 28?page=4\n",
      "Now scraping index 28?page=5\n",
      "Completed index 28?page=5\n",
      "Now scraping index 28?page=6\n",
      "Completed index 28?page=6\n",
      "Now scraping index 28?page=7\n",
      "Completed index 28?page=7\n",
      "Now scraping index 28?page=8\n",
      "Completed index 28?page=8\n",
      "Now scraping index 28?page=9\n",
      "Completed index 28?page=9\n",
      "Getting new pages\n",
      "['28?page=10']\n",
      "Now scraping index 28?page=10\n",
      "Completed index 28?page=10\n",
      "Getting new pages\n",
      "['6', '6?page=2', '6?page=3', '6?page=4', '6?page=5', '6?page=6', '6?page=7', '6?page=8']\n",
      "Now scraping index 6\n",
      "Completed index 6\n",
      "Now scraping index 6?page=2\n",
      "Completed index 6?page=2\n",
      "Now scraping index 6?page=3\n",
      "Completed index 6?page=3\n",
      "Now scraping index 6?page=4\n",
      "Completed index 6?page=4\n",
      "Now scraping index 6?page=5\n",
      "Completed index 6?page=5\n",
      "Now scraping index 6?page=6\n",
      "Completed index 6?page=6\n",
      "Now scraping index 6?page=7\n",
      "Completed index 6?page=7\n",
      "Now scraping index 6?page=8\n",
      "Completed index 6?page=8\n",
      "Getting new pages\n",
      "['31', '31?page=2', '31?page=3', '31?page=4', '31?page=5', '31?page=6', '31?page=7', '31?page=8', '31?page=9']\n",
      "Now scraping index 31\n",
      "Completed index 31\n",
      "Now scraping index 31?page=2\n",
      "Completed index 31?page=2\n",
      "Now scraping index 31?page=3\n",
      "Completed index 31?page=3\n",
      "Now scraping index 31?page=4\n",
      "Completed index 31?page=4\n",
      "Now scraping index 31?page=5\n",
      "Completed index 31?page=5\n",
      "Now scraping index 31?page=6\n",
      "Completed index 31?page=6\n",
      "Now scraping index 31?page=7\n",
      "Completed index 31?page=7\n",
      "Now scraping index 31?page=8\n",
      "Completed index 31?page=8\n",
      "Now scraping index 31?page=9\n",
      "Completed index 31?page=9\n",
      "Getting new pages\n",
      "['31?page=10', '31?page=11', '31?page=12', '31?page=13']\n",
      "Now scraping index 31?page=10\n",
      "Completed index 31?page=10\n",
      "Now scraping index 31?page=11\n",
      "Completed index 31?page=11\n",
      "Now scraping index 31?page=12\n",
      "Completed index 31?page=12\n",
      "Now scraping index 31?page=13\n",
      "Completed index 31?page=13\n",
      "Getting new pages\n",
      "['31?page=14', '31?page=15']\n",
      "Now scraping index 31?page=14\n",
      "Completed index 31?page=14\n",
      "Now scraping index 31?page=15\n",
      "Completed index 31?page=15\n",
      "Getting new pages\n",
      "['30', '30?page=2', '30?page=3', '30?page=4', '30?page=5', '30?page=6']\n",
      "Now scraping index 30\n",
      "Completed index 30\n",
      "Now scraping index 30?page=2\n",
      "Completed index 30?page=2\n",
      "Now scraping index 30?page=3\n",
      "Completed index 30?page=3\n",
      "Now scraping index 30?page=4\n",
      "Completed index 30?page=4\n",
      "Now scraping index 30?page=5\n",
      "Completed index 30?page=5\n",
      "Now scraping index 30?page=6\n",
      "Completed index 30?page=6\n",
      "Getting new pages\n",
      "['5', '5?page=2', '5?page=3', '5?page=4', '5?page=5', '5?page=6']\n",
      "Now scraping index 5\n",
      "Completed index 5\n",
      "Now scraping index 5?page=2\n",
      "Completed index 5?page=2\n",
      "Now scraping index 5?page=3\n",
      "Completed index 5?page=3\n",
      "Now scraping index 5?page=4\n",
      "Completed index 5?page=4\n",
      "Now scraping index 5?page=5\n",
      "Completed index 5?page=5\n",
      "Now scraping index 5?page=6\n",
      "Completed index 5?page=6\n",
      "Getting new pages\n"
     ]
    }
   ],
   "source": [
    "all_index_numbers = []\n",
    "all_categories = []\n",
    "for x,i in enumerate(category_index_numbers):\n",
    "    url = f'https://www.stilltasty.com/searchitems/index/{i}'\n",
    "    #Initial results pages\n",
    "    results_pages = [f'{i}']+get_index_numbers(url,\"/searchitems/index/\")[0]\n",
    "    results_pages = list(set(results_pages))\n",
    "    results_pages.sort()\n",
    "    new_pages = results_pages\n",
    "    while new_pages:\n",
    "        print(new_pages)\n",
    "        for j in new_pages:         \n",
    "            print(f\"Now scraping index {j}\")\n",
    "            url = f'https://www.stilltasty.com/searchitems/index/{j}'\n",
    "            index_numbers = get_index_numbers(url,\"/Fooditems/index/\")[0]\n",
    "            if index_numbers:\n",
    "                all_index_numbers = all_index_numbers + index_numbers\n",
    "                all_categories = all_categories + [categories[x]]*len(index_numbers)\n",
    "            print(f'Completed index {j}')\n",
    "            sleep(2)\n",
    "        #Check for additional pages\n",
    "        print('Getting new pages')\n",
    "        url = f'https://www.stilltasty.com/searchitems/index/{new_pages[-1]}'\n",
    "        results_pages = results_pages+new_pages\n",
    "        new_pages = [k for k in get_index_numbers(url,\"/searchitems/index/\")[0] if k not in results_pages]\n",
    "        new_pages = list(set(new_pages))\n",
    "        new_pages.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_index_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_index_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dict = {}\n",
    "for i in all_index_numbers[:3]:\n",
    "    # scrape_stilltasty(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Fruits': 223,\n",
       "         'Vegetables': 344,\n",
       "         'Dairy & Eggs': 197,\n",
       "         'Meat & Poultry': 350,\n",
       "         'Fish & Shellfish': 196,\n",
       "         'Nuts, Grains & Pasta': 229,\n",
       "         'Condiments & Oils': 182,\n",
       "         'Snacks & Baked Goods': 357,\n",
       "         'Herbs & Spices': 134,\n",
       "         'Beverages': 144})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_name': 'TURNIPS - FRESH, RAW',\n",
       " 'category': 'Vegetables',\n",
       " 'url': 'https://www.stilltasty.com/Fooditems/index/18595',\n",
       " 'shelf_life': {'Refrigerator': '2-3 weeks', 'Freezer': '8-10 months'},\n",
       " 'food_tips': 'Shelf Life Tips\\nHow long do raw turnips last? The precise answer to that question depends to a large extent on storage conditions - keep raw turnips refrigerated. \\r\\nTo maximize the shelf life of raw turnips, refrigerate in plastic bag.\\r\\nHow long do raw turnips last in the fridge? Properly stored, raw turnips will typically last for 2 to 3 weeks in the refrigerator. \\r\\nCan you freeze turnips? Yes, to freeze: (1) Wash, peel and cut into 1/2-inch cubes; (2) Blanch (plunge into boiling water) for two minutes and chill quickly in ice cold water; (3) Drain off excess moisture, package in airtight containers or freezer bags and freeze immediately. \\r\\nHow long do turnips last in the freezer? Properly stored, turnips will maintain best quality in the freezer for about 10 months, but will remain safe beyond that time. \\r\\nThe freezer time shown is for best quality only – turnips that have been kept constantly frozen at 0°F will keep safe indefinitely.\\r\\nHow to tell if raw turnips are bad or spoiled? The best way is to smell and look at the raw turnips: discard any raw turnips that have an off smell or appearance; if mold appears, discard the raw turnips. '}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_stilltasty('18595','Vegetables')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
